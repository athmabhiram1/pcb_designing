# AI Copilot for KiCad â€” Backend Dependencies
# Install: pip install -r requirements.txt

# Core Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0

# LLM Inference (pick ONE)
llama-cpp-python>=0.2.50       # Local GGUF inference
requests>=2.31.0               # For Ollama API fallback

# Data Validation
pydantic>=2.6.0

# Math (placement engine)
numpy>=1.26.0

# HTTP client (for Ollama health checks)
httpx>=0.26.0
